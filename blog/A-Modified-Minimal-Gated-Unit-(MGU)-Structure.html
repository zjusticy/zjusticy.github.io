<!DOCTYPE html><html><head><link rel="icon" type="image/png" href="/favicon.png"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-164183122-1"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-164183122-1', {
              page_path: window.location.pathname,
            });
          </script><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&amp;display=swap"/><title>A modified minimal gated unit (MGU) structure</title><meta name="description" content="An optimized structure of MGU after a logic analysis"/><meta name="next-head-count" content="5"/><link rel="preload" href="/_next/static/css/247593301584cfcb2949.css" as="style"/><link rel="stylesheet" href="/_next/static/css/247593301584cfcb2949.css"/><link rel="preload" href="/_next/static/css/f26d4875aca2643082fa.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f26d4875aca2643082fa.css"/><link rel="preload" href="/_next/static/OyX9zXWnaKsF3bwITkPiy/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/OyX9zXWnaKsF3bwITkPiy/pages/blog/%5Bslug%5D.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-c212667a5f965e81e004.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.126679bf45d7d49475d8.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.034e57c59893763d3595.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-d7ebbd1d8dc934d86683.js" as="script"/><link rel="preload" href="/_next/static/chunks/cb1608f2.3c307e8bab2014a7f3fb.js" as="script"/><link rel="preload" href="/_next/static/chunks/b5f2ed29.a17aa8175ac69602f508.js" as="script"/><link rel="preload" href="/_next/static/chunks/02a29bc1c6847a2903810fa698c0853380643ebd.eb7f86bcbbf58571f3fc.js" as="script"/><link rel="preload" href="/_next/static/chunks/411cb42639decf701111c98274b23dedc6e87d14.7504d1c9a7d74be7afa0.js" as="script"/></head><body><div id="__next"><div><nav class="navbar has-shadow" role="navigation" aria-label="main navigation"><div class="container"><div class="navbar-brand"><a class="navbar-item" href="/"><svg width="36" height="36" viewBox="0 0 144 142" aria-hidden="true" fill="#000" class="svg-icon " xmlns="http://www.w3.org/2000/svg"><rect x="124" y="81" width="20" height="20" fill="black"></rect><rect x="124" y="102" width="20" height="20" fill="black"></rect><rect x="41" y="20" width="20" height="20" fill="black"></rect><rect x="83" y="20" width="20" height="20" fill="black"></rect><rect x="62" y="122" width="20" height="20" fill="black"></rect><rect x="124" y="60" width="20" height="20" fill="black"></rect><rect y="81" width="20" height="20" fill="black"></rect><rect y="102" width="20" height="20" fill="black"></rect><rect x="62" width="20" height="20" fill="black"></rect><rect x="41" y="122" width="20" height="20" fill="black"></rect><rect x="104" y="122" width="20" height="20" fill="black"></rect><rect x="104" y="40" width="20" height="20" fill="black"></rect><rect x="83" y="122" width="20" height="20" fill="black"></rect><rect x="20" y="40" width="20" height="20" fill="black"></rect><rect x="20" y="122" width="20" height="20" fill="black"></rect><rect y="60" width="20" height="20" fill="black"></rect></svg></a><a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarBasicExample"><span aria-hidden="true"></span><span aria-hidden="true"></span><span aria-hidden="true"></span></a></div><div id="navbarBasicExample" class="navbar-menu"><div class="layout_navEndSettings__227S4 navbar-end"><a class="navbar-item layout_moreMargin__2KGfE" aria-label="Home page" href="/">Home</a><a class="navbar-item layout_moreMargin__2KGfE layout_addBorder__2Y_EI" aria-label="Blog page" href="/blog">Blog</a><a class="navbar-item layout_moreMargin__2KGfE" aria-label="About the author" href="/about">About</a></div></div></div></nav><main><div class="isBlog"><nav class="breadcrumb is-medium" aria-label="breadcrumbs"><ul><li><a href="/blog">Blog</a></li><li class="is-active"><span></span></li></ul></nav><article><h1 class="title is-2p5">A modified minimal gated unit (MGU) structure</h1><span class="dateStyle-2">10 Mar, 2021</span><div class="content"><div><p>Recurrent neural networks (RNNs) are versatile structures used in a variety of sequence data-related applications. The two most popular proposals are long short- term memory (LSTM) and gated recurrent unit (GRU) networks. Towards the goal of building a simpler and more efficient network, minimal gated unit (MGU) has appeared and shown quite promising results. We present a simple and improved MGU model, MGU_1 in this blog.</p>
<p>If you are not familliar with RNNs, you can check <a href="https://www.deeplearningbook.org/contents/rnn.html">this link</a>.</p>
<p>The code of this blog is on <a href="https://github.com/zjusticy/modified-minimal-gated-unit">Github repo</a>.</p>
<h2>MGU</h2>
<p>MGU is introduced to further lower complexity and maintain comparable accuracy when comparing to GRU. There are two gates in the GRU to control the data flow. As illustrated in the figure below, the reset gate <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">{r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span></span></span></span> and the update gate <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">{z}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span></span></span></span></span></span> both control the portion of input <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em"></span><span class="mord"><span class="mord mathnormal">x</span></span></span></span></span></span> and the previous hidden state  <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">{h_{t-1}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em"><span></span></span></span></span></span></span></span></span></span></span></span> in the current hidden state, there must be a correlation and redundancy between these two gates. Micro et al. [2] have proved the correlation by cross-correlation. Using the same value for the reset gate and update gate, therefore, is a natural operation. The MGU has only one gate - the forget gate (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{f_{t}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span></span>) - to represent the two gates above as below:</p>
<p><img src="/GRU.png" alt="GRU"/></p>
<p><img src="/MGU.png" alt="MGU"/></p>
<h2>MGU optimization</h2>
<p>In MGU model, when the forget gate <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{f_{t}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span></span> is 0, the previous hidden state will be cut off from flowing to the candidate hidden state <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>h</mi><mo>~</mo></mover></mrow><annotation encoding="application/x-tex">{\tilde{h}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9312999999999998em;vertical-align:0em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9312999999999998em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span></span></span><span style="top:-3.61344em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">~</span></span></span></span></span></span></span></span></span></span></span></span> (left switch is off). As a result, for the example below, the candidate hidden state only contains the input of the new story. We want to forget about the previous stories since it is a fresh start. However, for the switch on the right, when the forget gate <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">{f_{t}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span></span> is 0, the previous hidden state (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">{h_{t-1}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em"><span></span></span></span></span></span></span></span></span></span></span></span> ) - which contains previous stories - will be put through, and the candidate hidden state (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>h</mi><mo>~</mo></mover></mrow><annotation encoding="application/x-tex">{\tilde{h}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9312999999999998em;vertical-align:0em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9312999999999998em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span></span></span><span style="top:-3.61344em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">~</span></span></span></span></span></span></span></span></span></span></span></span>) - which contains the new story - will be drop off. This indicates that the logic of the two gates conflict with each other.</p>
<p><img src="/MGU_conflic.png" alt="MGU_1_conflic"/></p>
<p>The easiest way to solve this is to switch the pole of the right switch as below:</p>
<p><img src="/MGU_1.png" alt="MGU-3"/></p>
<h2>Experiment</h2>
<p>The PTB data set is widely used in natural language processing (NLP) research. We use this data set for the word prediction task and consider the model in [2]  as a reference. The size of the vocabulary is 10,000. It has 929k words for training and 73k words for validation. The model contains 2 layers of RNN and each has 200 hidden units. The time steps and batch size are set to 30 and 20 separately. A dropout layer is used and set the drop out rate to 0.2. Then a fully connected layer predicts one of the 10,000 words at the output.</p>
<p>The result of GRU, MGU and MGU_1 (optimized version) is shown in figure below. The performance of MGU_1 is on par with GRU and better than MGU. The MGU and MGU 1 layers both have 160,400 parameters in RNN layer, while the GRU layer has 241,200 parameters.</p>
<p><img src="/ptb_training_1.png" alt="Unknown-4"/></p>
<p><img src="/ptb_valid_1.png" alt="Unknown-3"/></p>
<h2>Conclusion</h2>
<p>Logic analysis can be one important process when we create a new RNN structure. Any logic conflict may lower the performance of the network.</p>
<p>By the way, in [2] they proposed a struture that removed the reset gate in GRU and only keep the update gate. I compare the performance of this proposal with the MGU_1. The former one is not as stable as the latter one (sometimes not converge). But when using Relu as the activation function, their performance is on par and they are both stable.</p>
<h2>Reference</h2>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/28297161">https://zhuanlan.zhihu.com/p/28297161</a></li>
<li><a href="https://github.com/wojzaremba/lstm">https://github.com/wojzaremba/lstm</a></li>
<li><a href="https://arxiv.org/abs/1803.10225">Light Gated Recurrent Units for Speech Recognition</a></li>
</ol></div></div></article><div class="marginTop-2"><a>← Blog</a></div></div></main><footer class="layout_myFooter__JubIR container"><div class="layout_footerStyle__2iYeS"><div><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="envelope" class="svg-inline--fa fa-envelope fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg>  <a href="mailto:tzhu618@gmail.com">tzhu618@gmail.com</a></div><div class="layout_lastColor__ALfcM">© <!-- -->2021<!-- -->, Built with<!-- --> <a href="https://nextjs.org/">NextJs</a> and <a href="https://bulma.io">Bulma</a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"A modified minimal gated unit (MGU) structure","date":"2021-01-10T09:40:32.169Z","description":"An optimized structure of MGU after a logic analysis","slug":"A-Modified-Minimal-Gated-Unit-(MGU)-Structure","content":"\nRecurrent neural networks (RNNs) are versatile structures used in a variety of sequence data-related applications. The two most popular proposals are long short- term memory (LSTM) and gated recurrent unit (GRU) networks. Towards the goal of building a simpler and more efficient network, minimal gated unit (MGU) has appeared and shown quite promising results. We present a simple and improved MGU model, MGU_1 in this blog. \n\nIf you are not familliar with RNNs, you can check [this link](https://www.deeplearningbook.org/contents/rnn.html).\n\nThe code of this blog is on [Github repo](https://github.com/zjusticy/modified-minimal-gated-unit).\n\n## MGU\n\nMGU is introduced to further lower complexity and maintain comparable accuracy when comparing to GRU. There are two gates in the GRU to control the data flow. As illustrated in the figure below, the reset gate ${r}$ and the update gate ${z}$ both control the portion of input ${x}$ and the previous hidden state  ${h_{t-1}}$ in the current hidden state, there must be a correlation and redundancy between these two gates. Micro et al. [2] have proved the correlation by cross-correlation. Using the same value for the reset gate and update gate, therefore, is a natural operation. The MGU has only one gate - the forget gate (${f_{t}}$) - to represent the two gates above as below:\n\n![GRU](/GRU.png)\n\n![MGU](/MGU.png)\n\n\n## MGU optimization\n\nIn MGU model, when the forget gate ${f_{t}}$ is 0, the previous hidden state will be cut off from flowing to the candidate hidden state ${\\tilde{h}}$ (left switch is off). As a result, for the example below, the candidate hidden state only contains the input of the new story. We want to forget about the previous stories since it is a fresh start. However, for the switch on the right, when the forget gate ${f_{t}}$ is 0, the previous hidden state (${h_{t-1}}$ ) - which contains previous stories - will be put through, and the candidate hidden state (${\\tilde{h}}$) - which contains the new story - will be drop off. This indicates that the logic of the two gates conflict with each other.\n\n![MGU_1_conflic](/MGU_conflic.png)\n\nThe easiest way to solve this is to switch the pole of the right switch as below:\n\n![MGU-3](/MGU_1.png)\n\n## Experiment\n\nThe PTB data set is widely used in natural language processing (NLP) research. We use this data set for the word prediction task and consider the model in [2]  as a reference. The size of the vocabulary is 10,000. It has 929k words for training and 73k words for validation. The model contains 2 layers of RNN and each has 200 hidden units. The time steps and batch size are set to 30 and 20 separately. A dropout layer is used and set the drop out rate to 0.2. Then a fully connected layer predicts one of the 10,000 words at the output. \n\nThe result of GRU, MGU and MGU_1 (optimized version) is shown in figure below. The performance of MGU_1 is on par with GRU and better than MGU. The MGU and MGU 1 layers both have 160,400 parameters in RNN layer, while the GRU layer has 241,200 parameters.\n\n![Unknown-4](/ptb_training_1.png)\n\n![Unknown-3](/ptb_valid_1.png)\n\n\n## Conclusion\nLogic analysis can be one important process when we create a new RNN structure. Any logic conflict may lower the performance of the network. \n\nBy the way, in [2] they proposed a struture that removed the reset gate in GRU and only keep the update gate. I compare the performance of this proposal with the MGU_1. The former one is not as stable as the latter one (sometimes not converge). But when using Relu as the activation function, their performance is on par and they are both stable.\n\n\n## Reference\n\n1. [https://zhuanlan.zhihu.com/p/28297161](https://zhuanlan.zhihu.com/p/28297161)\n2. [https://github.com/wojzaremba/lstm](https://github.com/wojzaremba/lstm)\n3. [Light Gated Recurrent Units for Speech Recognition](https://arxiv.org/abs/1803.10225)\n\n\n\n\n\n"}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"A-Modified-Minimal-Gated-Unit-(MGU)-Structure"},"buildId":"OyX9zXWnaKsF3bwITkPiy","nextExport":false,"isFallback":false,"gsp":true}</script><script nomodule="" src="/_next/static/runtime/polyfills-81f5c03661bad3d2f6ee.js"></script><script async="" data-next-page="/_app" src="/_next/static/OyX9zXWnaKsF3bwITkPiy/pages/_app.js"></script><script async="" data-next-page="/blog/[slug]" src="/_next/static/OyX9zXWnaKsF3bwITkPiy/pages/blog/%5Bslug%5D.js"></script><script src="/_next/static/runtime/webpack-c212667a5f965e81e004.js" async=""></script><script src="/_next/static/chunks/framework.126679bf45d7d49475d8.js" async=""></script><script src="/_next/static/chunks/commons.034e57c59893763d3595.js" async=""></script><script src="/_next/static/runtime/main-d7ebbd1d8dc934d86683.js" async=""></script><script src="/_next/static/chunks/cb1608f2.3c307e8bab2014a7f3fb.js" async=""></script><script src="/_next/static/chunks/b5f2ed29.a17aa8175ac69602f508.js" async=""></script><script src="/_next/static/chunks/02a29bc1c6847a2903810fa698c0853380643ebd.eb7f86bcbbf58571f3fc.js" async=""></script><script src="/_next/static/chunks/411cb42639decf701111c98274b23dedc6e87d14.7504d1c9a7d74be7afa0.js" async=""></script><script src="/_next/static/OyX9zXWnaKsF3bwITkPiy/_buildManifest.js" async=""></script><script src="/_next/static/OyX9zXWnaKsF3bwITkPiy/_ssgManifest.js" async=""></script></body></html>